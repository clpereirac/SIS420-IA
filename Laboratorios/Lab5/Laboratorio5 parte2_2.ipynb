{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfVg51ES7Aqp"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/juansensio/blog/blob/master/096_ml_unsupervised/096_ml_unsupervised.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSFYxTK87Aqy"
      },
      "source": [
        "# Aprendizaje Activo"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LABORATORIO 5 \"SIS420\" - APRENDIZAJE ACTIVO**\n",
        "\n",
        "*   Integrantes:\n",
        "\n",
        "*   Pereira Cuba Claudia\n",
        "*   Avendaño Cruz Adan\n",
        "*   Llaves Salas Angeles Joana\n",
        "*   Barja Coragua Erlinda\n",
        "*   Mamani Ramos Lizandro\n"
      ],
      "metadata": {
        "id": "2-dPs03u7ax4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aplicacion de aprendizaje activo\n",
        "En este ejercicio implementaremos el modelo con el Dataset.\n",
        "\n",
        "Nuestro objetivo es aplicar aprendizaje activo con imagenes de : 256x256 píxeles.\n",
        "En el siguiente dataset:\n",
        "\n",
        "Link del Dataset: https://www.kaggle.com/datasets/asaniczka/mammals-image-classification-dataset-45-animals\n",
        "\n",
        "Link del Repositorio de GitHub Lab-5: https://github.com/clpereirac/SIS420-IA/tree/main/Laboratorios/Lab5"
      ],
      "metadata": {
        "id": "g-Dy88Lg_AMW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Información del Dataset**\n",
        "Conjunto de datos de clasificación de imágenes de mamíferos (45 animales)\n",
        "\n",
        "Este conjunto de datos original contiene imágenes de 45 clases diferentes de mamíferos.\n",
        "### Acerca del conjunto de datos\n",
        "Las imágenes se encuentran en la estructura ImageNet, cada clase tiene su propia carpeta que contiene las imágenes respectivas. Las imágenes tienen una resolución de 256x256 píxeles.\n",
        "### Detalles del conjunto de datos:\n",
        "Para crear este conjunto de datos,\n",
        "\n",
        "Busqué cada clase de mamífero en Google Imágenes y extraje los enlaces de las imágenes.\n",
        "Luego descargué las imágenes de tamaño completo de la fuente original y las convertí al formato JPG con una resolución de 256 píxeles.\n",
        "Durante el proceso, la mayoría de las imágenes fueron reducidas de tamaño y solo unas pocas fueron ampliadas.\n",
        "Finalmente, revisé manualmente todas las imágenes y eliminé todas las que no encajaban bien en la clasificación de imágenes.\n",
        "\n",
        "### Posibles ideas de tareas:\n",
        "Entrene un modelo de clasificación de imágenes utilizando arquitecturas populares como ViT, ResNet o EfficientNet.\n",
        "Realice aprendizaje por transferencia en este conjunto de datos utilizando modelos previamente entrenados.\n",
        "Explore diferentes técnicas de aumento de datos para mejorar el rendimiento del modelo.\n",
        "Ajustar los modelos existentes para mejorar la precisión de la clasificación.\n",
        "Compare el rendimiento de diferentes modelos en este conjunto de datos.\n",
        "Utilice el conjunto de datos como referencia para evaluar nuevas técnicas de clasificación de imágenes.\n",
        "\n",
        "### Convención de nomenclatura de clases:\n",
        "Todos los archivos tienen nombres en estilo ImageNet.\n",
        "Kingdom\n",
        "├── class_1\n",
        "│   ├── class_1-0001.jpg\n",
        "│   └── class_1-0002.jpg\n",
        "├── class_2\n",
        "│   ├── class_2-0001.jpg\n",
        "│   └── class_2-0002.jpg\n",
        "└── class_3\n",
        "    ├── class_3-0001.jpg\n",
        "    └── class_3-0002.jpg\n",
        "Para obtener el nombre de la clase a partir de un nombre de archivo aleatorio, puede hacer .split('-')[0].\n",
        "No se a dividido el conjunto de datos en train,val,test para que puedas decidir las proporciones de división.\n",
        "\n"
      ],
      "metadata": {
        "id": "2d9u5pCu9BYo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Aprendizaje Activo**"
      ],
      "metadata": {
        "id": "V3TFu9_hAgDV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESb5KhYE7Aqy"
      },
      "source": [
        "El aprendizaje activo (o *Active Learning*) consiste en entrenar modelos de ML de manera iterativa, incluyendo en cada iteración nuevas muestras al dataset focalizando en ejemplos en loa que el modelo tenga más problemas."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importaciones necesarias\n",
        "from google.colab import drive\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import zipfile\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import time"
      ],
      "metadata": {
        "id": "PTCHBYDHtuhS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Montar Google Drive y extraer el ZIP\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Definir rutas\n",
        "zip_path = '/content/drive/MyDrive/datasets/archive.zip'\n",
        "extract_path = '/content/drive/MyDrive/datasets/archive/'\n",
        "\n",
        "# Extraer el archivo ZIP\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "print(\"Archivo ZIP extraído exitosamente\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0HgjXHh2hPv",
        "outputId": "31f18f37-e5ae-4001-c6f7-842f37c3b7db"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Archivo ZIP extraído exitosamente\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# PASO 3: Cargar y preprocesar las imágenes\n",
        "dataset_dir = '/content/drive/MyDrive/datasets/archive/mammals/'\n",
        "\n",
        "# Crear listas para almacenar datos\n",
        "imagenes_data = []\n",
        "etiquetas = []\n",
        "\n",
        "# Obtener clases (carpetas)\n",
        "clases = os.listdir(dataset_dir)\n",
        "print(f\"Número total de clases: {len(clases)}\")\n",
        "\n",
        "# Cargar imágenes (sin imprimir información de cada clase)\n",
        "for clase in clases:\n",
        "    ruta_clase = os.path.join(dataset_dir, clase)\n",
        "\n",
        "    # Verificar que la carpeta de la clase existe\n",
        "    if not os.path.exists(ruta_clase):\n",
        "        continue  # Saltar esta clase si la carpeta no existe\n",
        "\n",
        "    for archivo in os.listdir(ruta_clase):\n",
        "        if archivo.endswith('.jpg'):\n",
        "            try:\n",
        "                img = Image.open(os.path.join(ruta_clase, archivo))\n",
        "                img = img.resize((128, 128))  # Redimensionar para manejar memoria\n",
        "                if img.mode != 'RGB':\n",
        "                    img = img.convert('RGB')\n",
        "                img_array = np.array(img) / 255.0  # Normalizar\n",
        "                img_array = img_array.reshape(-1)  # Aplanar para LogisticRegression\n",
        "                imagenes_data.append(img_array)\n",
        "                etiquetas.append(clase)\n",
        "            except Exception as e:\n",
        "                pass  # Omitir cualquier error para no interrumpir el procesamiento\n",
        "\n",
        "# Convertir a arrays de numpy\n",
        "X = np.array(imagenes_data)\n",
        "y = np.array(etiquetas)\n",
        "\n",
        "# Mostrar el resumen final\n",
        "print(f\"Número total de imágenes procesadas: {len(X)}\")\n",
        "print(f\"Número total de etiquetas procesadas: {len(y)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poQI4KUy2jUw",
        "outputId": "88f4276c-113d-402e-d70a-15afdf6de464"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número total de clases: 45\n",
            "Número total de imágenes procesadas: 13751\n",
            "Número total de etiquetas procesadas: 13751\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir el conjunto de datos\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wg81WuAK7YA-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplanar las imágenes para la regresión logística\n",
        "X_train_flat = X_train.reshape(X_train.shape[0], -1)  # Aplanar las imágenes de entrenamiento\n",
        "X_val_flat = X_val.reshape(X_val.shape[0], -1)  # Aplanar las imágenes de validación\n"
      ],
      "metadata": {
        "id": "1Wzb90uw8dk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenar el modelo\n",
        "log_reg = LogisticRegression(multi_class=\"ovr\", solver=\"lbfgs\", max_iter=1000, random_state=42)\n",
        "log_reg.fit(X_train_flat, y_train)\n"
      ],
      "metadata": {
        "id": "-rfo453r9LmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predecir las probabilidades\n",
        "probas = log_reg.predict_proba(X_train_flat[:1000])  # Predecir para las primeras 1000 muestras\n"
      ],
      "metadata": {
        "id": "OIZghsv39PGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener el índice de la clase con la probabilidad más alta para cada muestra\n",
        "labels_ixs = np.argmax(probas, axis=1)\n",
        "\n",
        "# Crear un nuevo array labels que contiene las probabilidades más altas\n",
        "labels = np.array([proba[ix] for proba, ix in zip(probas, labels_ixs)])\n",
        "\n",
        "# Seleccionar las 10 muestras con las probabilidades más bajas\n",
        "sorted_ixs = np.argsort(labels)\n",
        "k = 10  # Número de imágenes a mostrar\n",
        "\n",
        "# Obtener las imágenes con las probabilidades más bajas\n",
        "X_lowest = X_train_flat[sorted_ixs[:k]]  # Asegúrate de que k no exceda la cantidad de imágenes\n",
        "\n",
        "# Crear la figura para las imágenes\n",
        "plt.figure(figsize=(15, 8))\n",
        "\n",
        "# Determinar el número de filas y columnas\n",
        "n_cols = 5  # Cambia a 5 columnas para mostrar mejor\n",
        "n_rows = (k // n_cols) + (k % n_cols > 0)\n",
        "\n",
        "# Iterar sobre las imágenes seleccionadas\n",
        "for index, img in enumerate(X_lowest[:k]):\n",
        "    plt.subplot(n_rows, n_cols, index + 1)\n",
        "    plt.imshow(img.reshape(64, 64, 3))  # Cambia a la forma original\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "JtmlOi8k9JMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_reg5 = LogisticRegression(multi_class=\"ovr\", solver=\"lbfgs\", max_iter=4000, random_state=42)\n",
        "%time log_reg5.fit(X_train_flat[:1000], y_train2)  # Asegúrate de que X_train_flat[:1000] esté disponible\n",
        "\n",
        "# Evaluar el modelo\n",
        "score = log_reg5.score(X_val_flat, y_val)\n",
        "print(\"Accuracy en el conjunto de validación:\", score)\n"
      ],
      "metadata": {
        "id": "IFfYAATj9YSQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "74dbfc52f168b3071122cf9c0781887d6121c12f9c1b29bca56ce221bccb2a07"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}