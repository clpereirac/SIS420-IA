{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0w0R7w45myY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ruta de la carpeta mammals: E:\\IA\\mammals\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Definir la ruta base del dataset\n",
        "ruta_base = 'E:\\\\IA'  # Cambia a la ruta de tu disco\n",
        "ruta_principal = os.path.join(ruta_base, 'mammals')  # Ruta a la carpeta mammals\n",
        "\n",
        "# Crear una lista para almacenar los arrays de imágenes, nombres de archivo y etiquetas\n",
        "imagenes_data = []\n",
        "nombres_archivos = []\n",
        "etiquetas = []  # Para almacenar las etiquetas (nombres de las carpetas)\n",
        "\n",
        "# Verificar que la ruta existe\n",
        "if os.path.exists(ruta_principal):\n",
        "    print(f'Ruta de la carpeta mammals: {ruta_principal}')\n",
        "else:\n",
        "    print(\"La ruta de mammals no existe. Verifica la ruta.\")\n",
        "\n",
        "# Iterar sobre las imágenes en el directorio y subdirectorios\n",
        "for root, dirs, files in os.walk(ruta_principal):\n",
        "    for archivo in files:\n",
        "        if archivo.endswith('.jpg'):\n",
        "            # Construir la ruta completa del archivo\n",
        "            ruta_archivo = os.path.join(root, archivo)\n",
        "            try:\n",
        "                # Abrir la imagen\n",
        "                img = Image.open(ruta_archivo)\n",
        "                # Convertir la imagen a escala de grises\n",
        "                img = img.convert('L')\n",
        "                # Convertir la imagen a un array de numpy y aplanar\n",
        "                img_array = np.array(img).flatten()\n",
        "                # Añadir el array al dataset y el nombre del archivo\n",
        "                imagenes_data.append(img_array)\n",
        "                nombres_archivos.append(archivo)\n",
        "                # Añadir la etiqueta (nombre de la carpeta)\n",
        "                etiqueta = os.path.basename(root)  # Obtiene el nombre de la carpeta\n",
        "                etiquetas.append(etiqueta)\n",
        "            except Exception as e:\n",
        "                print(f'Error al abrir {ruta_archivo}: {e}')\n",
        "                continue\n",
        "\n",
        "# Convertir la lista de imágenes a un array de numpy\n",
        "data = np.array(imagenes_data)\n",
        "\n",
        "# Aplicar KMeans para clustering\n",
        "n_clusters = len(set(etiquetas))  # Cambia según el número de categorías únicas\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "kmeans.fit(data)\n",
        "\n",
        "# Obtener etiquetas asignadas\n",
        "etiquetas_kmeans = kmeans.labels_\n",
        "\n",
        "# Crear un DataFrame con los datos, etiquetas y nombres de archivo\n",
        "df = pd.DataFrame(data)  # Crear DataFrame a partir de los datos de imágenes\n",
        "df['Etiqueta'] = etiquetas_kmeans  # Añadir la columna de etiquetas\n",
        "\n",
        "# Guardar el DataFrame en un archivo CSV\n",
        "df.to_csv('dataset_imagenes_con_etiquetas.csv', index=False)\n",
        "\n",
        "print('Etiquetas guardadas en dataset_imagenes_con_etiquetas.csv')\n",
        "\n",
        "# Separar en X (características) e y (etiquetas)\n",
        "X_final = df.drop(['Etiqueta'], axis=1)  # Características (imágenes)\n",
        "y_final = df['Etiqueta']  # Etiquetas\n",
        "\n",
        "# Mostrar las dimensiones de X e y\n",
        "print(f'Dimensiones de X: {X_final.shape}, Dimensiones de y: {y_final.shape}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hola\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(X_train.head())\n",
        "print(X_test.head())\n",
        "print(y_train.head())\n",
        "print(y_test.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "probas = log_reg3.predict_proba(X_train[:1000])\n",
        "# Devuelve el índice de la clase con la probabilidad más alta para cada muestra\n",
        "labels_ixs = np.argmax(probas, axis=1)\n",
        "# Aquí se crea un nuevo array labels que contiene las probabilidades más altas para cada muestra,\n",
        "# utilizando los índices de labels_ixs\n",
        "labels = np.array([proba[ix] for proba, ix in zip(probas, labels_ixs)])\n",
        "# DFinalmente, se seleccionan las 10 muestras con las probabilidades más bajas (es decir, las más inciertas)\n",
        "# al indexar labels con los primeros 10 índices de sorted_ixsevuelve los índices que ordenarían el\n",
        "# array labels en orden ascendente.\n",
        "sorted_ixs = np.argsort(labels)\n",
        "labels[sorted_ixs[:10]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_lowest = X_train.values[500:1000][sorted_ixs[:k]]\n",
        "\n",
        "# Asegúrate de que k sea un número positivo\n",
        "k = min(k, len(X_lowest))  # Asegúrate de que k no exceda la cantidad de imágenes a mostrar\n",
        "\n",
        "# Crea la figura para las imágenes\n",
        "plt.figure(figsize=(15, 8))  # Aumenta el tamaño de la figura\n",
        "\n",
        "# Determina el número de filas y columnas\n",
        "n_cols = 2  # Cambia a 5 columnas para mostrar mejor\n",
        "n_rows = (k // n_cols) + (k % n_cols > 0)  # Calcula el número de filas\n",
        "\n",
        "# Itera sobre las imágenes seleccionadas\n",
        "for index, img in enumerate(X_lowest[:k]):  # Asegúrate de limitar a k imágenes\n",
        "    plt.subplot(n_rows, n_cols, index + 1)  # Usa n_rows y n_cols\n",
        "    plt.imshow(img.reshape(64, 64), cmap=\"binary\", interpolation=\"bilinear\", aspect='auto')  # Cambia a 64x64\n",
        "    plt.axis('off')  # Elimina los ejes\n",
        "\n",
        "# Ajustar el espaciado entre subgráficas\n",
        "plt.tight_layout()  # Esto ayuda a evitar superposiciones\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Obtiene las primeras 1000 etiquetas del conjunto de entrenamiento\n",
        "# Es un array que contiene los índices de las probabilidades clasificadas\n",
        "y_lowest = y_train.values[:1000][sorted_ixs[:k]]\n",
        "# seleccionas las etiquetas que corresponden a esas imágenes de baja probabilidad\n",
        "y_lowest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# es un array que contiene las etiquetas propagadas para las imágenes de entrenamiento (etiquetas asignadas\n",
        "# automaticamente)\n",
        "y_train2 = y_train_propagated[:1000].copy()\n",
        "# sorted son los índices de las imágenes con las probabilidades más bajas de clasificación\n",
        "# estás reemplazando las etiquetas de las imágenes de baja probabilidad (que están en y_train2 en esos índices)\n",
        "# con las nuevas etiquetas que has obtenido y almacenado en y_lowest\n",
        "y_train2[sorted_ixs[:k]] = y_lowest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "log_reg5 = LogisticRegression(multi_class=\"ovr\", solver=\"lbfgs\", max_iter=4000, random_state=42)\n",
        "%time log_reg5.fit(X_train[:1000], y_train2)\n",
        "log_reg5.score(X_test, y_test)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
